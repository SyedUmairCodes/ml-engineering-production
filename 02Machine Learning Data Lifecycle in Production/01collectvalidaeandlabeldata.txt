# Overview
Hey, and welcome to collecting, labeling, and validating data. This course is all about data and not just data, but data in a production machine learning setting, you'll discover that there are quite a few differences between production data and data that you might have been using in, an academic or research environment and that's what this course is all about. I'm really excited to get started, so let's get going. We've got some really important stuff to talk about this week. This week is all about data, collecting our data, labeling it, and validating it. Let's get started before we jump in. I know there maybe some of you who are coming from a more academic or research setting who might be thinking data? I already know all about data what am I going to learn here? Well, in production environments, you discover some interesting things about the importance of data. Hear two quotes from ML practitioners had businesses where Data and ML is mission-critical. Talking about how they view the importance of data. First, from Uber, Data is the hardest part of ML and the most important piece to get right. Broken data is the most common cause of problems in production ML Systems and next from Gojek, no other activity in the machine learning lifecycle has a higher return on investment than improving the data a model has access to. The truth is that if you go to just about any production ML team and ask them about the importance of data. You'll get similar answers. So that's why we're talking about data because it's incredibly important to success and the issues for data in production environments are very different from the academic or research environments that you might be familiar with. Okay, now that we've got that out of the way, let's dive in. So this is our Introduction to Machine Learning for production and we're going to start with an overview. Let's get started by establishing what Machine Learning and Production is? And how you can view Production ML really as a combination of ML development and modern software development practices? We'll also discuss some of the challenges that are unique to Production ML. In an academic or research setting, modeling is really fairly simple. Well, maybe not simple, but perhaps less complicated. Anyway, typically you have some dataset, often standard dataset that supplied to you and already cleaned and labeled and you're going to use that to train your model and evaluate the results. The end result is a model that makes good predictions. So you'll probably go through a few iterations to fully optimize the model. Once you're satisfied with the results, then typically you're done. Production ML requires a lot more than just a model. We found that the model is typically about 5 percent of the code required to put an ML application into production. Take a look at all the other boxes that are in this diagram and you'll get some idea about what we're going to be talking about. Fundamentally, we're not just talking about machine learning and modeling. We're talking about Production ML applications and what it takes to create them, deploy them, maintain them, and improve them so that you can make them available to your users and your business or your organization if you're doing something like a non-profit. Let's compare some of the differences between ML modeling in a researcher, academic setting and real production ML. To start with, in an academic or research environment, you're typically using a static dataset for Production ML real-world data is used, which is dynamic and usually shifting. The design priority for academic or research ML is usually the highest accuracy over the entire training set but the design priority for Production ML is fast inference and good interpretability and of course, accuracy and cost. Model training for research ML is based on a single optimal result and the tuning and training necessary to achieve it. Production ML requires continuous monitoring, assessment, and retraining. Interpretability and fairness is very important for any ML modeling, but it's absolutely crucial for Production ML. Finally, while, the main challenge of academic and research ML is finding intuiting, a high-accuracy model. For production ML the challenge is that plus everything else, the entire system.
Play video starting at :5:38 and follow transcript5:38
It would be fair to say that you can look at Production Machine Learning as both machine learning itself and the knowledge and skillset required and modern software development. It really requires expertise in both areas to be successful, because you're not just producing a single result, you're developing a product or service that is often a mission critical part of your offering. ML development itself focuses on specific issues related with the data and the quality of predictions. For example, assuming that you're doing supervised learning, then you need to make sure that your labels are accurate, and you also need to make sure that your training dataset has examples which cover the same feature space as the request that your model will receive. You also want to reduce the dimensionality of your feature vector to optimize your system performance, while retaining or enhancing the predictive information on your data. Throughout all of this, you need to consider and measure the fairness of your data and model, especially for rare conditions, for example, in domains such as health care, where rare but important conditions may be absolutely critical to success. But on top of all of that, you're putting a piece of software into production that requires a system design, that includes all of the things that are required for any production software deployment. Of course, this deployment has to be focused on ML and your application. Is your system scalable? Can you scale it both up and down? Can you extend it cleanly to add new stuff when you need to? Does it have a clear, well-defined configuration? Is it consistent? Can you reliably reproduce results? Is it hardened against attacks? Is the design modular? Following modern software development principles. Can you test individual units? Can you do end-to-end testing? Can you continuously monitor the health and performance of your system and be alerted when there are problems? Have you adopted industry best practices? Using a model in real-world applications requires much more than just an understanding of machine learning algorithms. The first step is scoping, which focuses on defining the project needs and goals and the resources required to achieve them. Next, you start working on your data, which defining the features that you're going to use well as organizing and labeling your data. That may sometimes include measuring human level performance to set a baseline for comparison. Then you design and train a model. In this phase, error analysis will help you refine your model to suit your project's needs. After training your model, you deploy it so that it can be used to serve prediction requests. You might deploy your model on mobile devices, on a Cloud, or in IoT devices, or even in a web browser. Over time, real-world data continuously changes, which can result in a degradation of your model performance. You need to continuously monitor the performance of your model, and if you measure a drop in performance, you need to go back to model retraining and tuning, or revise your data. During deployment, new data may affect your project design either positively or negatively and risk coping might be necessary. Ultimately, all these steps create your production ML system, which needs to run automatically such that you're continuously monitoring your model performance, ingesting new data, and retraining as needed, and then redeploying to maintain or improve your performance. The challenges when doing production ML are very different than academic or research ML, or in some sense they're the same but include a lot more.
Play video starting at :10:13 and follow transcript10:13
You're going to be building an integrated system specifically focused on ML use cases. You need to think about operating it continuously in production, and for online use cases, that means it has to stay available 24/7. You've got to think about and put systems in place, to handle a changing world and changing data, and of course, like any production system, you need to try to do all of this at the minimum cost while producing the maximum performance. It might seem daunting, but the good news is that there are well-established tools and methodologies for doing this, and we'll be covering many of those in this course.

# ML Pipelines
Welcome back. This next section is all about ML Pipelines. No, not those kind of pipelines. Machine Learning Pipelines. ML Pipelines are the heart of any Production ML system. You're going to learn all about them right now. In this lesson, we'll begin to introduce ML Pipelines and the concept of MLOps. Now allow us to see how pipeline orchestrators sequence and schedule ML tasks to implement the entire ML training process. We'll then look at the example of TensorFlow Extended or TFX, which is a widely adopted framework for creating ML Pipelines. What do we mean by the phrase ML Pipeline? Well, remember the iterative ML workflow that we talked about previously. ML Pipeline is a software architecture to implement exactly that. Automating, monitoring, and maintaining this ML workflow from data to a trained model. ML Pipelines form a key component of MLOps architectures. This slide shows one version of what an ML Pipeline looks like, which was put together by an industry group, the CD Foundation. There are some differences between different pipeline architectures, but in general they look something like this. You'll notice that they basically mirror the ML development process. Starting with data ingestion and ending with a trained model. That's by design since they need to encapsulate and formalize that process. ML Pipelines are almost always directed cyclic graph or DAGs. Although in some advanced cases they can sometimes includes cycles. A DAG is a collection of all the tasks you want to run sequenced in a way that reflects their relationships and dependencies. Notice that in this graph the edges are directed and there are no cycles. That makes this graph a DAG. Orchestrators are responsible for scheduling the various components in an ML Pipeline based on dependencies defined by a DAG. Orchestrators help with pipeline automation. Examples include Argo and Airflow, and Celery and Luigi and Kubeflow. TFX is an open-source end to end Machine Learning platform, and it's what we use at Google. A TFX Pipeline is a sequence of scalable components that can handle large volumes of data. Starting on the left, we ingest data and then we move to Data Validation and we do some feature engineering. We train a model, we validate it. If it's better than what we already have in production, we're going to push it to production. Finally, we're serving predictions. The sequence of components are designed for scalable high performance Machine Learning tasks. In this course, you'll be using TFX to implement real ML Pipelines exactly as you would for Production Systems. TFX in production components are built on top of open-source libraries, such as Tensorflow Data Validation, which you'll also learn about later this week. Tensorflow Transform. We shall also be working with extensively later in this course and others, like Tensorflow Model Analysis. Components in the orange here, leverage those Libraries and form your DAG as you sequence these components and set up the dependency between them, you create your DAG, which is your ML Pipeline. This is what we refer to as the Hello World of TFX. We start on the left with our data and we're going to ingest our data with a TFX component called ExampleGen. All the boxes in orange that you see here are TFX components. In fact, these are components that come with TFX when you just do a PIP install. Next, we generate statistics for our data. We want to know the ranges of our features, if they're numerical features, if they're categorical features, we want to know what are the valid categories and so forth. What are the types of our features? Example Validator is used to look for problems in our data. SchemaGen is used to generate a schema for our data across our feature vector. Transform will do feature engineering. Tuner and Trainer are used to train a model and to tune the hyper-parameters for that model. Evaluator is used to do deep analysis of the performance of our model. We'll talk about what we mean by deep analysis a little bit later. Infra Validator is used to make sure that we can actually run predictions using our model on the infrastructure that we have. For example, do we have enough memory? If all of that passes and the model actually performs better than what we might already have in production. Then Pusher pushes the model to Production. What does that mean? Well, we might be pushing to a repository like Tensorflow HUB and then using our model later for maybe transfer learning. We're generating Embeddings. We could be pushing to TensorFlow JS. If we're going to be using our model in a web browser or a Node.js application. We could push to TensorFlow Lite and use our model in a mobile application or on an IOT device. Or we could push to TensorFlow Serving and UserModel on a server or maybe a serving cluster. The key points here, first of all, Production ML Pipelines are more than just ML code. They're ML development and software development and a formalized process for running that sequence of tasks end to end, in a maintainable and scalable way. TFX is an open-sourced end to end ML platform that we'll be using in this course.

# Importance of data
Hi and welcome back, well to actually do any machine learning, you need to have some data. Where do you get that data, well in production ML it turns out you usually have to find ways to collect that data, and we'll talk all about that right now. Now let's discuss collecting data and a little bit about the importance of data, to first let me tell you a story about an application that I was involved in. We were asked to create a model to predict the amount of time that it would take to get through an airport security checkpoint on different days at different times with different lines of different lengths and so forth. So we need a data, and how are we going to get that data, well we had to measure how long it took people to get through security checkpoints. How are we going to measure that, well, what it came up with is we had to actually go to the airport, we had to get someone cleared through security because anything you do in an airport has to be approved by the security. We had one person standing at the beginning of the line to get into a security checkpoint and they would record the time that somebody entered. And then we had another person standing at the other end, the exit of the checkpoint, and actually they were far enough away from each other. They couldn't even see each other, and they would record the time that each person left. And in that way we would gradually build up a data set of labeled data that gave us the amount of time that people took to get through an airport security checkpoint. Well, as you can imagine, it was incredibly painful, we had to develop applications just to support being able to do that. And it was incredibly expensive, we had to pay people they had to be cleared through security and so forth. So when we talk about collecting data in the real world, hopefully you're not going to deal with a situation like that. But it will be a real world situation where you need to think about how you're going to get the data you need unless, you're very lucky and somebody already has the data for you, which is great. And if that's the case, that's wonderful, so let's start by discussing the importance of data and the importance of data quality. It's your your data and your model is only going to be good as good as the quality of your data. If there's a lot of noise in your data, then you need to try to deal with that, if the labels especially are noisy, then there you have to find ways to try to clear up that signal. We're going to be using data pipelines almost exclusively because remember we need to automate these processes. So we're going to need data collection and then in our pipeline we're going to ingest and prepare. Our data has sequenced automated tasks, and we're going to need to monitor data collection. So remember for most applications, you don't just collect data once you are going to collect data throughout the lifetime of that application. As we've seen, data is the hardest part of ML and the most important piece to get right. This is a quote from Uber, broken data is the most common cause of problems in production ML systems. Well, i hope you never have to learn that the hard way, Gojek has similar feelings about that. And really if you go to just about any production machine learning team, they'll tell you stories about collecting data and and how important it is to get the data right. In programming language design, a first called citizen is a in a given programming language is an entity which supports all the operations generally available to other entities, and an ML data is a first class citizen. So software one data was all about code, it's it's really just, the instructions for the computer, in software two dato, we need to specify a goal and for the behavior of the program, the code is important, but not the only thing that we worry about, optimization is really the driving force here. So optimization in a lot of different directions. So we want to optimize for performance, obviously what we want to optimize for maintain ability and scalability as well. And for ML data is data quality is really critical for success, so in some ways you could look at it as, data is is almost like the software almost like a code in a software window application. Data is sort of a similar sort of player in an ML application. So the cartoon on the right shows one way to look at this, you I'll let you read there by yourself, but models aren't magic. So it's good for you to know that the data that you have, you could have mountains of data, but if it if it doesn't have predictive content, then, you're just not going to be able to create a predictive model with it. So there's a couple things here, you you want to remove information from your model and features from your model that aren't predictive, because they're going to cause problems are certainly going to take a lot of compute resources that you don't want to be spending on that. And you need to make sure supervised learning case or even unsupervised learning, that your training data is really covering the same feature space as the as the prediction requests that you'll get when you put your model into production. You need to cover that same space so that your model has good information about the regions of that space to make predictions and, just like anything, it's garbage in and garbage out. So if your data is garbage, if your data quality is low your model and your application will, be low quality. The good news actually for ML is that we can measure that in a lot of software applications. You, it might not be as easy to measure how bad your solution or good your solution is doing, but in the end well it's it's pretty easy to measure that. So data collection is an important and critical first step to building ml systems and data. You want to avoid problems with downtime, you need to make sure that your training a model that you can scale, that you can serve predictions and you need to think about, especially for things like time series, you have things like seasonality and trends. You need to think about different kinds of errors and what we'll talk about all of these. But it's this whole picture that you need to sort of keep in your mind when you're you're developing things that it's going to be an entire process, from ingestion through serving and that all has to be automated. It all has to be testable and maintainable and scale well and so forth, so you need to understand your users and you need to make sure that you're translating the user needs into data problems. You don't want to just do the model that you happen to have if it doesn't meet the needs of the user.
Play video starting at :7:58 and follow transcript7:58
You need to make sure that your data covers the same region of your feature space as the prediction request that you'll get your training data and you want to make sure that you've really maximize the predictive signal in that data. And you need to worry about the data quality not just at the beginning but throughout the life of the application. So part of that is making sure that your sourcing data responsibly and you're thinking about things like bias and fairness, which we will talk about later on in this course.

# Example Application: Suggesting Runs
Now let's talk about collecting data and look at an example application. For this example, we're going to be looking at an application that suggests runs to runners. There's different runners with different level of fitness. The first step is really to try to understand the users as we've discussed. This system is going to suggest runs based on the user's behavior and by leveraging observed patterns and preferences. The goal is to improve the consistency of running and for runners to complete those runs and to really be happy about that.
Play video starting at ::47 and follow transcript0:47
Some key considerations. First of all, you need to consider data quality and data collection. What kind of data and how much data do you need? How often do you need new data? When do you expect things to change? Is that data annotated? You also need to translate the user needs into data needs. Understand the user's grade but at the end of the day we do need features and data. We need to first understand the user because otherwise we run the risk of collecting a bunch of data that is really just garbage. But once we understand the user, then we need to translate the user needs into data needs. We're going to do that with identifying what the data is, what the features are and what the labels are. Here's an example data set. We've got three different examples here for three different kinds of runs and we've got some features. The examples here are the Boston Marathon, the Seattle Oktoberfest 5K and the Houston Half-marathon. The 5K sounds good to me, I'm that kind of a runner. The features well, the Run itself, the Runner Time and the Elevation, which is also important. Then the labels here are just going to be how the runner rates the fun level of those runs. It looks like they agree with me that the 5K sounds like it'd be a lot of fun. Get to know your data. You need to identify the data sources that you're going to use, where are you going to get this data and not just the first time but on an ongoing basis? It's not just the training but you need to collect that same data, for you not to do inference when you want to create a prediction. You need to think about, how often do I need to refresh my trainings at? Along the way when you're working with your data, you need to make sure that there's actually predictive value, in your data. Anyone trying to make sure that you've eliminated features and data that does not have predictive value. But there's also some more basic things like, is the data consistent? When you're expecting, say a float do you always get a floater or is it mixed? Looking for things like outliers too or just errors. Because remember, you're dealing with systems you could have a sensor that goes bad and then you got an error. There could be data issues coming from different measurements, different types and also simple things like the difference between an end to the float or how missing value is encoded, that can all cause problems. In this example data set, if the elevation is zero feet, does that really mean that we're at sea level or does it mean that we don't have any elevation data for that record?
Play video starting at :3:57 and follow transcript3:57
If the output is coming from other ML models maybe if you're using an ensemble. If there's errors in those, then you can compound those errors when you try to use it in a downstream model. You also want to make sure that you're looking for errors and issues early in the process and monitoring the data sources for system issues and outages. Because remember, we're operating this thing, could be 24-7 easily, a lot of things are. Also, you need to expect to have system issues and outages. What if the app was offline for a while and the recorded runner time is wrong for some number of users, do you have ways to deal with that? Measuring the data effectiveness, you need some intuition about the data value, but your intuition can be misleading. You really need to make sure that you're looking at which data is really giving you the most information. Feature selection and feature engineering are really critical to shaping your data to be what you need it to be. The feature engineering will help you maximize the predictive signals once you've really identified where those are. Feature selection, that helps you measure where that predictive information is and really focus in on those features that give you the most value and help your model the most. Again, user needs. You need to understand the user and the application and in this case, we're looking at running data from an app. We can get demographic data when the user fills out their profile and we also probably can get some GPS data to give us some local geographic information. At high level that helps us understand the user. Then we need to translate that into features. The runner demographics, we need to express that as a feature or probably several features. Things like the time of day, how long it takes them to complete a run, their pace during the run, the distance and so forth, the elevation and if we're working with an app that has some sensors like a heart rate monitor, that's great information to have to really feed into this app, probably has some predictive information. But again, we need to test that. What our labels going to be? Runner acceptance in this case is a label that we want to focus on. Runners that take our suggestions and use them. That tells us that the app successfully gave them a run that they wanted to do and conversely, if they rejected it. User-generated feedback. You need to think about, first of all, how they're going to give you that feedback in a structured way that you can use to help with training your model. Then you know things like user rating. In this case of the enjoyment of the recommended runs. Again, it needs to be in a form that we can use. It can't just be free form unless you're going to do NLP to try to understand their paragraph of feedback but typically you're not going to do that. But anyway, the point here is that you need to understand the data and your user and how you're going to apply the labels. Key points: understand your user or your application, if there is no user, translate their needs into data problems and well-defined features that give you predictive information. What kind of data can you get? What's available? What are the details and issues for your data? Things like sensors. How reliable are they? Where's the predictive information in your data? It may not be where you think it is, it sometimes isn't. What are the labels? We need to make sure that we're training a model to predict the right thing. We need to make sure our labels are the correct ones for our goals. That's going to get to the metrics. What are the metrics that we're going to use to measure the performance of our model?

# Responsible Data: Security, Privacy & Fairness
One of the key aspects of collecting data is to make sure that you're collecting it responsibly and paying attention to things like security, privacy and fairness. Let's talk about that now. So we're going to be looking at how to responsibly sourced data and ensure that our data is secure and that we're managing user privacy correctly. We need to know how to check for and ensure fairness and we need to design labelling systems that will mitigate bias. So here's an example. These images here show one standard open source image classifier trained on the open images data set that does not properly apply wedding related labels to images of wedding traditions from different parts of the world. On the far left, the classifiers, label prediction is recorded as ceremony, Wedding, bride, man, group, woman, dress. So that's pretty correct. The next one is bride ceremony, wedding, dress and woman. Again we know that's correct at least in the west, that's what a bride typically looks like. The next one over is good as well. So it's ceremony and bride and wedding, man, groom, woman, dress again, gets it right. But the one on the end, the one on the right. Well, that's for an African wedding ceremony, but it's incorrectly labeled as simply person or people. Well, it is person your people, but it's also a ceremony and there's a bride and a groom and address and so forth. So this is a classic case it's an example it's often cited of a problem with bias in the data set. So an ML system, the data may come from different sources and you need to think about those sources as well in your day to say it's not just the data that you have but where did you get it from? So you might be building synthetic data, you might be doing web scraping your often collecting live data, especially when you're running inference. You're often almost always really going to be building your own data set, although sometimes you can be using an open source data set. It just depends on what's available and what you need. But data security and privacy or key, they're always going to be important. Data security that really refers to the policies and methods and means to secure personal data or what's often referred to as PII, Personally Identifiable Information. Data privacy is about proper usage, collection retention, deletion and storage of that data.
Play video starting at :3:4 and follow transcript3:04
So data collection is not just about your model. You need to think about your users and treat that data as something that has been given to you to be a steward of your taking care of that data you need to manage it responsibly. Users really should have control over which data is being collected. And it's important to establish mechanisms to prevent your system revealing a user's data inadvertently or even through a tax. So how you handle your data privacy and data security depends on the nature of your data as well as the operating conditions and regulations and policies, things like GDP are very important here. Users privacy is also really key. So you need to protect personally identifiable information or data. Well, there's different ways to do that. Aggregation really helps with that if you can aggregate the data so that you can identify individual people within it, anonymous, rising it and giving users control over what data they share. Also, a good good way to deal with that. You need to consider any laws or regulations regarding user privacy that might be affecting in the places where you're going to be using your model and redaction. So in a lot of cases you need to give users a way to remove some of the data, which will create a less complete picture but is part of being responsible with your data.
Play video starting at :4:44 and follow transcript4:44
So ML Systems can fail users in a lot of different ways and we need to strike a balance between being fair and accurate and transparent and explainable.
Play video starting at :4:58 and follow transcript4:58
Some of the ways that ML Systems can fail are through things like representational harm. So representational harm is where a system will amplify or reflect a negative stereotype about particular groups. Opportunity denial is when a system makes predictions that have negative real life consequences that could result in lasting impacts. Disproportionate product failure is where the effectiveness of your model is really skewed so that the outputs happen more frequently for particular groups of users, you get skewed outputs more frequently essentially can think of as errors more frequently. Harm by disadvantage is where a system will infer disadvantageous associations between different demographic characteristics and the user behaviors around that. So fairness is important and you should really commit to it from the beginning. So what does it mean? Well, being fair means that you're going to identify if some groups of people get a different experience than others in a problematic way. So for instance, let's assume particular gender or occupation or age fields or part of your data and that you use it to train a model that predicts whether someone would be a reliable new employee. So it's involved in hiring. You need to really check to make sure that your model does not consistently predict different experiences for some groups in a problematic way by ensuring group fairness. So what that means is demographic parody and that things are equalized across different groups. And you need to make sure the accuracy as well is equal or or as close as you can get it. The data collected and labeled by humans will reflect their biases in many cases and their personal experiences so you have to account for that. Diversifying your user base is a good way to move towards fairness, but it's not a guarantee. So ML Systems can amplify biases. You need to be aware of that and be careful about it and you really what you want to do is deploy fair models. Biases can also arise when you have disproportionate representation of some groups within your data or no representation at all. So looking at the graphic here, what we're trying to show is that part of the people that are shown here are in your data, but there's a whole lot of other people who are not. So those groups might be stereotyped the ones that are not in your data or they might just be presented in a less positive way, or they may just get a bad experience a lot more often. So to reduce bias for supervised learning, you need accurate labels to train your model and serve predictions.
Play video starting at :8:10 and follow transcript8:10
The labels are usually coming from two broad sources. It depends there's other sources as well, but most of the time they're going to be coming from automated systems or human Raters, and we'll talk about both. Humans are able to label data in different ways. And the more complicated the data is, the more you may require an expert to look at that data and we'll talk about that in a bit. So humans that label data are referred to as Rater's. So who are raters? Well, they could be generalists and these are people who just pretty average people who are going to be adding labels through a variety of crowdsourcing tools. And these are cases where it's fairly easy for people to recognize the correct label. So for example, if you want a human to recognize the difference between a cat and a dog, that's something most people can do by looking at the image. But in some cases you really need a subject matter expert. So in those cases you're often using specialized tools and an example of that is is looking at X rays for diagnosis. It's not something that just anyone can do. You need to make sure that you're working with an expert and that labelling tends to get pretty expensive. So a subject matter expert or domain expert, this is something that you need in certain cases. You can also use your users. So this sort of feedback that we looked at for our running app. This can often be very valuable if you can find a way to work without in your application and it's going to give you this ongoing stream of labels for your data if you can make that work.
Play video starting at :9:57 and follow transcript9:57
So key points, first of all, always account for fair Raters and fair representation in your data set to avoid potential biases. And take into account who those labelers are and what their incentives are, because if you design the incentives incorrectly, you could get a lot of garbage in your data. The cost is certainly always going to be an important consideration. So if you can find a way to do it with a high level of quality but at less cost, that's great. But you need enough data. You need to find a way to do that. It's one of the challenges of production applications and finally data freshness too. You're going to be working with data and depending on how the world changes around the application and the data that you have, you're going to need to refresh that data on some regular basis and detect when you need to do that. So those are all issues you need to think about to really manage collection of data and to do it in a responsible way.

# Case Study: Degraded Model Performance
Welcome back. The only constant in the universe is change. That quote is actually attributed to Heraclitus of a thesis in 500 BC. And I think it's fairly safe to say that it's still true today and it affects production amount. So for example if you had trained a model a few years ago to recognize what a book looks like, it might have looked like this. If you train a model today, you'd also want to include books that look like this. Let's find out more now.
Play video starting at ::37 and follow transcript0:37
To illustrate some of the issues with labeled data in performance settings, let's take a look at a case study.
Play video starting at ::46 and follow transcript0:46
So imagine that you're an online retailer and you're selling shoes and you have a model that predicts click through rates which helps you to decide how much inventory to order.
Play video starting at :1:1 and follow transcript1:01
And suddenly the AUC and prediction accuracy have dropped not on everything but on a particular part of your inventory. Men's dress shoes. Okay. Why? You trained your model? You did fairly well in your metrics and so forth. Why is it different? What changed? Why does your model not predict men's dress shoes well now? And perhaps more importantly, how do you even know that you have a problem? Your models still running? It's still giving predictions. You're still ordering inventory. How do you know that the orders that you're making and the predictions that your model is giving you are not as good as they used to be? Well, unfortunately, if you don't put good practices into place in the production setting, you're probably going to find out either when you order way too many shoes or not enough shoes. And that's not a situation that you want to be in in a business. This is going to cost you money.
Play video starting at :2:9 and follow transcript2:09
So you need to think about how you're going to detect problems like that early. And what the possible causes are so that you can look for those and monitor your system. And then try to have methods systems in place to deal with those problems when they happen because they probably will happen at some point.
Play video starting at :2:34 and follow transcript2:34
But what kinds of problems? Well, there's different kinds and they tend to fall into two different categories. There are slow problems. So for example, your data will drift over time as the world changes and seasons pass and you have holidays and competitors enter or change what have you. And then you have fast problems that are really part of your system. So you have a sensor that goes bad or you have a software update that gets applied and suddenly things are wonky. So you need to really be monitoring your system well and looking for both of those problems and thinking about remediation in both cases. For gradual problems, they tend to fall into two groups really, but they're interrelated too so it's not like there's a hard line between them. Trend and seasonality for example, especially in time series you will have trends and you will have seasonality in most cases and you could argue about whether that's really a change in data or a change in the world. Same thing with the distribution of the features. Again, it's something that you see in your data. And the relative importance of features can change too as the relative importance changes, if you haven't retrained your model accuracy starts to decay.
Play video starting at :4:10 and follow transcript4:10
The world also changes constantly. And in production settings that has to become part of the systems that you design and the processes that you have in place. Things like, well, if we're working in retail and we're just looking at an example with shoes, styles change. So, maybe last year black shoes were really fashionable for men's dress shoes and now it's brown shoes or what have you. The scope and the processes change. So your understanding of those processes and how they happen in the world will affect how your model views the results of those processes. Competitors change and your business also changes. So you may take on new products, you may end of life other products you may have new competitors, you may expand into other geography ease or you may move out of geography, ease prices from suppliers change, prices on the open market, change all of that affects how your model needs to adapt to the world. And this tends to be very domain specific, but in general, in nearly all domains, changes in the world affect your model performance. So for sudden problems, there's things that you're probably familiar with. So data collection problems, things like a bad sensor or bad camera, the log data suddenly changes and you have a different format or the logs themselves are may be rotated differently, you can have a sensor or a camera that doesn't really change, but it moves. Maybe it gets bumped or maybe someone decided it should be in a different spot. I personally have seen that happen where we had cameras that someone decided that they should be moved and didn't tell us about that. [LAUGH]. Systems problems. So you're going to have software updates all the time and if they change something significant that you weren't aware of, that can be a real problem. Network connectivity. No, no, the network never goes down, does it? Well, maybe sometimes it does. Systems too. Whole systems can go down. So be aware of that. [LAUGH]. And bad credentials, you sign credentials and often they time out or something changes about them, all those things can cause a sudden problem that all of a sudden it's a fire drill and you need to deal with it.
Play video starting at :6:59 and follow transcript6:59
So part of this is really trying to understand your model and how it's sensitive to different changes in the world. A big issue here is that miss predictions don't have uniform cost to your business. Some miss predictions will have very little effect on your business. Other miss predictions could have huge effects. So understanding that and really as you're monitoring things, looking for things that have larger impacts is important. The data you have as you collect data is rarely the data that you wish you had. So I've personally seen cases where we were using sensor data from wifi devices and it was not great data. It was really noisy and but it was all we had. It was all we could have. So we had to work with what we had. The model objective is almost always a proxy for what you're really trying to get to. In many cases, sometimes you can design a model and you have the data to design a model for exactly the thing that you're trying to attack. But often, as in the case of the shoes that we just looked at, we were predicting click through rates as a proxy for deciding how much inventory to order. Some percentage of your customers will have a bad experience. You want that percentage to be as small as possible and as much as possible, you want to understand which customers those are going to be, so that you can try to design ways to mitigate that and improve the situation for all of your customers. But the bottom line here that you will deal with constantly is that the real world does not stand still. The one constant in the world is change.

# Data and Concept Change in Production ML
In our discussion of labeling data, let's take a look at data and concept change in production ML. We're going to be talking about detecting problems with deployed models. Really that focuses on two things, data change and concept change or world change. There's different kinds of this. We've talked about a little bit of this, we'll get into it some more. There are different kinds of changing ground truth. There's easy problems, there's harder problems, and then you get really hard problems and you need different approaches to deal with these. Let's look at them. Detecting problems with deployed models, you can look at the data and the scope of the data and the world in a couple of different ways, but fundamentally, you need to monitor your models and you need to validate the results and the data of your models to find problems. You want to try to find problems early especially with system problems that happen quickly like a bad sensor or things like that, that we've discussed. But a fundamental issue is changing ground truth. What that means is that you need to label new data over the life of your application. It depends on really the domain that you're working in and the kinds of problems that you're trying to solve as far as what approaches are really feasible for doing that. There are easy problems. Things like, trying to recognize images of cats and dogs. In this case, the ground truth really changes pretty slowly. Model retraining in those cases is usually driven by model improvements, you are better at recognizing cats or dogs, or whatever it is that you're doing. You could have changes in software too. You could be upgrading things or using a different library, that kind of thing, or systems. Labeling in this case is fairly simple, you're going to work with maybe a curated dataset that you're getting from some public domain source or a source that your organization has been using for awhile or you could look at crowd-based as well. If it tends to be fairly simple, things like feedback, of course, if you have those available, great, use them. Use what you can. Then we get into a little harder problems where the ground truth really changes faster. Things like styles. We looked at shoes, but there's a lot of things where styles. The world changes on a matter of maybe weeks, that kind of thing. Model retraining in that case is usually driven by declining model performance, which you need to measure if you're going to be aware of. You can also have model improvements, you can also have better data and of course, the software and systems you're running on can also change. But as these things get harder, you get more things and declining model performance is one of those. Labeling in this case, if you can do direct feedback either from your systems or from your users, that's great. Crowd-based human labeling is another feasible way of doing this, since you do have probably weeks to respond. You can take a pass through human raters to do that. Really hard problems though, it becomes well, really hard. In this case, ground truth changes very fast, like on order of days or hours or even minutes. Things like markets really fall into this category, they change very quickly. In this case, declining model performance is definitely going to be a driver for when you need to retrain your model. You can also have things like model improvements and changes in software and so forth, but those tend to be things that you'll be working on offline while you're keeping your application running. It's really model performance where you really need well-defined processes to deal with those changes. Labeling in this case becomes very challenging. Direct feedback is great if you can do it in your domain. If not, you need to look at things like week supervision that we'll talk about. But it's really challenging in these kinds of domains. They tend to be high-value domains. Things like predicting markets where there's significant incentive to doing these predictions. The key points of what we're talking about here, model performance decays over time. It may decay slowly over time, in things like cats and dogs, that doesn't change very quickly, or it may change very fast, things like markets. Model retraining will help you improve or maintain your performance. Certainly as your model performance decays, it'll help you do that. Data labeling, assuming you're doing supervised learning, which is pretty common, data labeling is a key part of that. You really need to think about how you're going to approach that in your particular problem, in your particular domain and with the systems that you have available to you.

# Process Feedback and Human Labeling
Let's look at some ways to generate labels for your data. We're going to focus on two of the most common methods. That's process feedback or direct labeling and human labeling. There's a variety of methods, process feedback or direct labeling is great and we'll talk about that. Human labeling as well as a very common method is applied to create labels. But you should also be aware and we'll talk about later some other more advanced methods, semi-supervised labeling, where we label part of our data set, active learning where we really try to focus on the part that is most important. Weak supervision which is a programmatic way of creating labels. But we won't be talking about that in this module. We'll really focus on the first two, which are the most common, process feedback or direct labeling and human labeling. You need labels if you're going to do supervised learning, you need labels for your data. Two simple ways of doing that are processed feedback and human labeling. But what does that mean? Let's look at some examples, for process feedback, a very typical example is click-through rates. Actual versus predicted click-through rates. Suppose you have recommendations that you are giving to a user, did they actually click on the things that you recommend? If they did, you can label it positive, if they didn't you can label it negative. Human labeling, you can have humans look at data and apply labels to them. For example, you can ask cardiologists to look at MRI images and apply labels to them. Why is labeling important in production ML? Most businesses and organizations have a bunch of data, but if it's not labeled, you can't use it for supervised learning. If you can apply unsupervised techniques and get good results, that's great. But in many cases you really need to provide learning to solve the problems that you're trying to solve. What that means is that in most domains you're going to need to retrain at some point. It will depend as we've talked about on the domain that you're working in and the type of problem. Some you will just need to retrain on a very infrequent basis, and some, you might need to retrain several times per day. Labeling is an ongoing and often critical process in your application and your business. But at the end of the day, creating a training data set for supervised learning requires labels, you need to think about how you're going to do that. Direct labeling, which we'll talk about first or process feedback, is a way of continuously creating new training data that you're going to use to retrain your model. You're taking the features themselves from the inference requests that your model is getting. The predictions that your model is being asked to make and the features that are provided for that. You get labels for those inference requests by monitoring systems and using the feedback from those systems to label that data. One of the things that you need to solve there is to join the results that you get from monitoring those systems with the original inference request which could be hours or days apart. You might've run batches on Monday and you're getting feedback on Friday. You need to make sure that you can do those joins to apply those labels. In some ways you can think about this as similar to reinforcement learning, where instead of applying rewards based on action you're applying labels based on a prediction. It's a similar feedback loop. The advantages, well process feedback or direct labeling is great. If your system and your domain is set up in a way that you can do that. It's often the best answer because you have labels you are monitoring, constantly getting new training data. The signals that you get from your labels are really strong. You're getting for click-throughs, if the user clicked or didn't click, it's a very strong signal. Disadvantages, unfortunately, in many domains for many problems, it's just isn't possible. Personally, in the problems I've been asked to solve, I found very few or I've been able to do that, so that's an issue. The other big thing is that it tends to be very custom-designed. Your systems will be unique. Your problem is unique, and you're doing custom design, which isn't the end of the world, but it'd be great if it was a little bit more off the shelf. One of the tools that you can apply is log analysis tools. Because often when you're doing process feedback, the data is coming from the log files. You're monitoring systems and populating log files. One good open source tool for doing that is Logstash. You can ingest from multiple sources for collecting and parsing and storing logs. You can index them in ElasticSearch. You can push them to storage, it takes inputs from a variety of different sources and databases and so forth. Great tool and it's open source too. Fluentd is another good open source tool you can use to collect and parse. Fluentd comes from the Cloud Native Computing Foundation and it connects to a lot of different platforms. Again, another great tool. When you're working on the Cloud, there's Cloud tools that are available, as well. If you're working on the Google Cloud, Google Cloud logging is a great tool to be able to log your data, either coming from Google Cloud or from AWS. Bind plane is great for applying on-premise or hybrid cloud systems. It's a very powerful service that's available. For AWS, their version of Elasticsearch is available, so you can apply that. It's not really strictly a log analytics tool but you can apply it for login analytics. For Azure, you have Azure monitors, so regardless of which Cloud you're working on, there's probably log analytics tooling that you can use to do log analysis. Now, let's turn to human labeling. In human labeling, you have people, humans and we refer to those as raters. We ask them to examine data and assign labels to it. It sounds simple, it sounds like it might be painful but it's the way that a lot of data is generated and labeled. You start with raw data and you give it to people and you ask them to apply labels to it. That's the way that you create a training data set that you're going to use to train or retrain your model. You started with unlabeled data and then you need to recruit human raters or there are several services that you can go to where they have pools of human raters that have already been recruited. You need to provide them with instructions. Even if it's very simple, you need to still tell them what labels they should apply and what to look for to decide which label to apply. The data's then divided among different raters in the pool. Often you send the same examples to multiple raters, so that when there's disagreements you're aware of that and you can work to resolve them. Then you collect the data and any of those conflicts that you have are resolved. Advantages of the human labeling. Well, they're labels which, it's what you're trying to do. You're trying to generate labels which you need for supervised learning. It's a way to do that and it's actually a very common way to do that. One disadvantage, one issue here is that depending on the data that you have it can be very complex for a human to look at it and decide what the label should be. Something like this we might need a radiologist to look at this and tell us what the right labels should be which can be very expensive. But if you're also talking about situations where you have high dimensional data, it's very difficult for humans to look at say, 100 different features and decide with the label is. There's some disadvantages to human labeling. You can have quality problems where different humans disagree on what the label should be. It can be very slow. You're asking people to look at each individual example and it can take a while to do that. In cases where the data's changing quickly, it is often just simply not feasible. Again, it can be very expensive even if you're using generalists to look at very simple data, you're still employing people but in cases where you're asking experts to look at data then it gets very expensive. Often what that means is that you end up with small data sets because the cost and the time involved results in difficult to get a very large data set. It can be slow, it can be difficult, it can be expensive. If you're doing something like an MRI and you've got a specialist looking at it again, a problem. A single rater can only do a certain number of examples per day, so you need to have a fairly large pool compared to the number of examples that you're trying to label and that means that recruitment can be slow and expensive. Unfortunately, there are several disadvantages. Key points here, there's various methods of doing labeling and you really need to think about the problem that you're trying to solve, the data that you have and how frequently you need retraining data and how much data you need and the costs involved. There are advantages and disadvantages to both process feedback in human labeling and there's other techniques, as well that we'll talk about later.

# Detecting Data Issues
Hello and welcome back. You've probably heard the phrase garbage in, garbage out. Well, that's very true for Production ML. You can have a live data. But if your data isn't good, well it's not good for ML either. How do you know? How do you know your data is good or isn't good? Let's find out right now. Now let's look at validating data and detecting data issues and really look at trying to understand what issues we need to deal with. We need to detect data issues, and we often talk about drift and skew. We're going to be discussing Data and concept Drift and Schema Skew and Distribution Skew, and how to go about conceptually detecting data issues. First of all, let's get some definitions out of the way, drift and skew. Drift is changes in data over time. For example, data collected once a day over time, maybe a week later, a month later, there are changes that data has drifted. Skew is the difference between two static versions from different sources of conceptually the same dataset. For example, it could be the difference between your training set and the data that you're getting for prediction requests, your serving set. Those differences are referred to as skew. In a typical ML pipeline, this shows batch processing, but it could also be online processing. You'll have different sources of data that are conceptually the same. They have the same feature vector, but over time they will change. That means that model performance can either drop quickly due to things like system failure or can decay over time due to changes in the data and things like changes in the world. We're going to focus on performance decay over time that arises due to issues between training and serving data. There's really two main reasons for that. There's Data drift, which are changes in the data between training and serving typically and Concept drift, which are changes in the world changes in the ground truth. To understand model decay over time, an ML model will start to perform poorly in many cases and we refer to this as model decay. That's usually or often caused by drift, which is changes in a conceptual way. There is changes in the statistical properties of the features. It's sometimes due to things like seasonality or trend or unexpected events, or just changes in the world. This example here, we're looking at an app that during training the app classified as a spammer, any user who is sending 20 or more messages per minute. We classified anybody like that as a spammer. But after a system update which you see as labeled on the chart there, both spammers and non-spammers start to send more messages. In this case, the data, the world has changed and that causes unwanted misclassification. We have all of our users are classified as spammers which they probably won't like. Concept drift is a change in the statistical properties of the labels over time. At training, an ML model learns a mapping between the features and the labels. In a static world that's fine, that won't change. But in real-world, distribution and the labels meaning will change. The model needs to change as well as the mapping found during training will no longer be valid. As you previously see, there are many factors that cause changes over time including upstream data changes and seasonality and evolving business processes. Schema skew occurs when the training and scheming as serving data do not conform to the same schema, which you might think could never happen but actually it can because you're collecting data and things change and suddenly you're getting an integer where are you expecting a float. Or you're getting a string where you are expecting a category. Distributions skew is a divergence of training and serving data sets. The data set shift can be really manifested by covariant and concept and other types of shifts. We'll talk about that in a second. Skew detection involves continuous evaluation of data coming to your server once you train your model. To detect these changes, you need continuous monitoring and evaluation of the data. Let's take a look at a more rigorous definition of the drift and skew that we're talking. Dataset shift occurs when the joint probability of x are features and y are labels is not the same during training and serving. The data has shifted over time. Covariate shift refers to the change in distribution of the input variables present in training and serving data. In other words, it's where the marginal distribution of x are features is not the same during training and serving, but the conditional distribution remains unchanged. Concept shift refers to a change in the relationship between the input and output variables as opposed to the differences in the Data Distribution or input itself. In other words, it's when the conditional distribution of y are labels given x are features is not the same during training and serving, but the marginal distribution of x are features remains unchanged. There's a straightforward workflow to detect data skew. The first stage is looking at training data and computing baseline statistics and a reference schema. Then you do basically the same with your serving data, you're going to generate the descriptive statistics. Then you compare the two. You compare your serving baseline statistics and instances. You check for differences between that and your training data. You look for skew and drift. Significant changes become anomalies and they'll trigger an alert. That alert goes to whoever's monitoring system, that can either be a human or another system to analyze the change and decide on the proper course of action. That's got to be the remediation of the way that you're going to fix and react to that problem.

# Tensorflow data validation
Now that you've seen some of the data issues and detection workflows and got an idea of the importance of productions scale data validation. Let's take a look at TensorFlow Data Validation, which is a library from Google as part of the TFX Ecosystem. It'll allow you to do data validation using Python and we'll do an exercise doing that. TensorFlow Data Validation or TFDV, helps developers understand, validate, and monitor their ML data at scale. TFDV is used to analyze and validate petabytes of data at Google every day across hundreds or thousands of different applications that are currently in production. TFDV helps TFX users maintain the health of their ML pipelines. TFDV helps generate data statistics and provides browser visualizations. It also helps infer the schema for your data, but you will need to make sure that that schema makes sense. It'll do an inference that is best effort. Once it has these statistics and schema, it can look for problems are anomalies in your data. Then it will look at the training serving skew by comparing the data in your training and your serving datasets. One of the common use cases is continuously checking newly arriving data by validating it against the expectations which you have in the reference schema that you generated from your training data. The typical setup uses the schema, which is maintained over time, and the statistics are computed over new data and those statistics are used to validate the data against the original schema. Remember, we talked about skew detection and with TFDV you can easily detect three different types of skew, schema skew, feature skew, and distributions skew.
Play video starting at :2:16 and follow transcript2:16
TFDV performs skew or drift detection on categorical features and skew is expressed in terms of an L-infinity distance, which is also known as Chebyshev distance. If you think of a chessboard, it's the distance metric that is the maximum absolute distance in one-dimension of two n-dimensional points. You can set thresholds so that you'll receive warnings when the drift is higher than what you think is acceptable. Schema skew occurs when the serving and training data don't conform to the same schema. For example, it could be a change in type, an int, where you're expecting a float, which could be a change in the feature itself. Feature skew are changes in the feature values between training and serving. It could happen as the system uses different data sources during training and serving or things change or of course, things like seasonality and trend as well. Sometimes that simply because you have two different code paths and you're trying to do the same transformations, both when you trained your model and when you're serving your model using two different code paths and you're getting different results as a consequence. There's ways to avoid doing that and we'll talk about that later. Distribution skew is changes in the distribution of individual features in the dataset. Features that's in training might have a range of 0-100 when you're training it and then at serving time, you're seeing data between 5-600. That would be a change in the distribution for that feature. You got to have things like changes is the mean or the median or the standard deviation changes, all of those are changes in distribution. Depending on how severe it is, it may or may not be a problem. The question is, does it affect your model performance enough that you need to make changes to try to account for it? TFDV provides you with descriptive statistics at scale. Remember, we could be working with petabytes of data. It provides some visualizations as well to help you monitor and really understand that data. Trying to understand the underlying statistics for your data and do comparisons. How does your training and evaluation and serving datasets compare? Just in terms of statistics, for example, do they have the same mean? How can you calculate and fix or detect rather and fix data anomalies. We did a lot here. Just to wrap up, this week, you saw differences between ML modeling in academic or research environments and production ML systems. We discussed responsible data collection and how to really approach building a fair production ML system. We learned about process feedback and direct labeling and also human labeling. We looked at some of the issues that you can have with data and how to identify and detect those issues. Now, we're going to be practicing Data Validation with TFDV, TensorFlow Data Validation in this week's exercise notebook. You'll be testing your skills with the programming assignment by generating datasets, statistics, and creating and comparing and updating data schemas. Good luck.